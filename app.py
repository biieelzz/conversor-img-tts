import streamlit as st
import cv2
import easyocr
import pyttsx3
from PIL import Image
import numpy as np
import os


# Fun√ß√£o para carregar e exibir a imagem
def carregar_imagem():
    with st.container(border=True):
        st.subheader("Envio de imagem üñºÔ∏è", divider="rainbow", anchor=False)
        st.write('\n')
        # Prompt para o usu√°rio carregar a imagem
        imagem_enviada = st.file_uploader("Envie uma imagem ou capture uma foto para extrair texto e ouvir sua convers√£o em fala",
                                          type=["jpg", "jpeg", "png",
                                                "bmp", "tiff", "webp"]
                                          )

        # Exibindo a imagem na tela
        if imagem_enviada:
            imagem = Image.open(imagem_enviada)
            st.image(imagem, caption="Imagem carregada", use_column_width=False)

            # Convertendo a imagem carregada do formato PIL (utilizado pelo Streamlit) para o formato OpenCV (matriz NumPy)
            # Alterando o espa√ßo de cores de RGB para BGR, que √© o padr√£o utilizado pelo OpenCV
            return cv2.cvtColor(np.array(imagem), cv2.COLOR_RGB2BGR)

        return None


# Fun√ß√£o para extrair texto da imagem
def extrair_texto_imagem(imagem):
    st.write('\n')
    st.write('\n')
    with st.container(border=True):
        # Subt√≠tulo dentro do streamlit
        st.subheader("Extra√ß√£o de texto üìÑ", divider="rainbow", anchor=False)
        st.write('\n')

        # Iniciando o leitor do easyocr
        # Suporte para portugu√™s e ingl√™s
        leitor = easyocr.Reader(['pt', 'en'])

        # Salvando o texto em uma vari√°vel
        resultados = leitor.readtext(imagem)

        # Concatenando os textos detectados
        texto_extraido = " ".join([resultado[1] for resultado in resultados])

        # Mostrando em tela o texto extra√≠do
        st.write(texto_extraido)

        return texto_extraido


# Fun√ß√£o para converter texto em fala e salvar localmente
def converter_texto_fala(texto):
    # Convertendo o texto em fala e salvando em um arquivo de √°udio local
    # Retornando o caminho do arquivo de √°udio gerado
    if not texto.strip():
        st.error(
            "O texto est√° vazio. Certifique-se de que a imagem cont√©m texto leg√≠vel.")
        return None

    try:
        # Iniciando o conversor de texto para fala
        engine = pyttsx3.init()

        # Definindo diret√≥rio onde o √°udio ser√° salvo
        diretorio_audio = "audios"
        if not os.path.exists(diretorio_audio):
            # Criando o diret√≥rio caso ele n√£o exista
            os.makedirs(diretorio_audio)

        # Definindo o nome do arquivo de √°udio
        arquivo_audio = os.path.join(
            diretorio_audio, "audio_convertido.mp3")

        # Salvando o √°udio no diret√≥rio local
        engine.save_to_file(texto, arquivo_audio)
        engine.runAndWait()

        return arquivo_audio

    except Exception as e:
        st.error(f"Erro ao converter texto para fala: {e}")
        return None


# Fun√ß√£o main do app
def main():
    # Configura√ß√£o da p√°gina
    st.set_page_config(
       page_title="Conversor IMG > TEXT/TTS",
        page_icon="üíª",
    )

    # Informa√ß√µes da barra lateral
    avatar = "images/Gabriel.jpg"
    with st.sidebar:
        st.image(avatar, use_column_width=False)
        st.markdown("Desenvolvido por :violet[**Gabriel Oliveira**]")
        st.write("\n")
        st.write("\n")
        st.write("\n")
        st.write("\n")
        st.write("\n")
        st.write("\n")
        st.write("\n")
        st.markdown("**LinkedIn:** https://bit.ly/3Op4te9")
        st.markdown("**GitHub:** https://bit.ly/4g1kNOe")

    st.header("Conversor de :red-background[imagens] para :blue-background[texto] e :violet-background[fala]", anchor=False)
    st.write('\n')
    st.write('\n')

    # Carregando imagem
    imagem = carregar_imagem()

    if imagem is not None:
        # Extraindo texto da imagem
        texto_extraido = extrair_texto_imagem(imagem)

        if texto_extraido:
            # Convertendo texto em fala e criando um player no streamlit
            caminho_audio = converter_texto_fala(texto_extraido)

            if caminho_audio:
                # Lendo o arquivo de √°udio salvo localmente em modo bin√°rio
                with open(caminho_audio, "rb") as audio_file:
                    audio_bytes = audio_file.read()

                st.write('\n')
                st.write('\n')
                with st.container(border=True):
                    # Subt√≠tulo dentro do streamlit
                    st.subheader("Convers√£o para Fala üó£Ô∏è", divider="rainbow", anchor=False)
                    st.write('\n')

                    # Criando o player de √°udio
                    st.audio(audio_bytes, format="audio/mp3")

            else:
                st.warning("N√£o foi poss√≠vel gerar o √°udio.")


# Execu√ß√£o do app
if __name__ == "__main__":
    main()
